{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## PLEASE RUN THE FOLLOWING CODE FOR PRE-PROCESSING THE FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/jay/DATA/learn/udacity-dend/udacity-data_modeling-cassandra\n"
     ]
    }
   ],
   "source": [
    "# checking your current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get your current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "    #print(file_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "# reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    " # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "# uncomment the code below if you would like to get total number of rows \n",
    "#print(len(full_data_rows_list))\n",
    "# uncomment the code below if you would like to check to see what the list of event data rows will look like\n",
    "#print(full_data_rows_list)\n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Part II. Apache Cassandra coding portion\n",
    "\n",
    "## The event_datafile_new.csv contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font>:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# This should make a connection to a Cassandra instance your local machine \n",
    "# (127.0.0.1)\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster()\n",
    "\n",
    "# To establish connection and begin executing queries, need a session\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.Session at 0x7fef3b44e8d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    session.execute(\"\"\"\n",
    "    CREATE KEYSPACE IF NOT EXISTS sparkifydb \n",
    "    WITH REPLICATION = \n",
    "    { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\"\"\"\n",
    ")\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    session.set_keyspace('sparkifydb')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Queries\n",
    "\n",
    "### Question 1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "Question 1 expects Names of the artists, titles of the songs and lengths of the tracks based on sessionId and itemInSession.\n",
    "As we are working with a NoSQL database, we need to think about the query first which will be used to fetch the data based on which we will create the Table required.\n",
    "\n",
    "1) The expected output is: \"Name of the artist, title of the song and length of the track\"\n",
    "2) Based on: \"sessionId and itemInSession\"\n",
    "\n",
    "From the above two points we know the query to get the data will be a SELECT statement like (camelcase converted to snake_case):\n",
    "\n",
    "```\n",
    "SELECT artist_name, song_title, song_length FROM music_library_by_sessions WHERE session_id = value AND item_in_session = value\n",
    "```\n",
    "\n",
    "As we know the SELECT query, we can move to CREATE table query.\n",
    "\n",
    "Before creating the table, we DROP the existing table if it exists, to ensure we start from a clean slate (i.e. to avoid any issue if the code is run twice).\n",
    "\n",
    "We will add NOT EXIST to the CREATE statement to check if the table exists and only create the table if it does not exist. Now we need to select the columns that are going to be in the table and the PRIMARY KEY.\n",
    "\n",
    "(Named: music_library_by_sessions as per Rubric requirements for tables names as alphanumeric; also as the details of the table is for songs and indexed by sessions, it sounds apt to name the table 'music_library_by_sessions')\n",
    "\n",
    "Column Names: We need names of the artists, titles of the songs, and lengths of the tracks on query upon sessionId and itemInSession. Hence we will select artist_name, song_title , song_length, session_id and item_in_session as the names of the columns.\n",
    "\n",
    "Primary Key: The PRIMARY key for the table should uniquely identify each row in the table. For us we need results based on sessionId and itemInSession; so we need these both as the primary key (Selecting one will throw filtering error on \"SELECT * FROM music_library_by_sessions WHERE session_id = 338 and item_in_session = 4\", as we have not set item_in_session in primary key; also filtering is not allowed for the project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# CREATE\n",
    "\n",
    "query = \"DROP TABLE IF EXISTS music_library_by_sessions\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "query = \"\"\"CREATE TABLE IF NOT EXISTS music_library_by_sessions\n",
    "           (session_id int, item_in_session int, artist_name text, song_title text, song_length float, PRIMARY KEY (session_id, item_in_session))\"\"\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# INSERT\n",
    "\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO music_library_by_sessions (session_id, item_in_session, artist_name, song_title, song_length)\"\n",
    "        query = query + \" VALUES (%s, %s, %s, %s, %s)\"\n",
    "        session.execute(query, (int(line[8]), int(line[3]), line[0], line[9], float(line[5])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Do a SELECT to verify that the data have been inserted into each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(artist_name='Faithless', song_title='Music Matters (Mark Knight Dub)', song_length=495.30731201171875)\n"
     ]
    }
   ],
   "source": [
    "# SELECT\n",
    "\n",
    "query = \"SELECT artist_name, song_title, song_length FROM music_library_by_sessions WHERE session_id = 338 AND item_in_session = 4\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "    for row in rows:\n",
    "        print (row)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Question 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "\n",
    "Question 2 expects names of the artists, titles of the songs and users' full names based on userId and sessionId, and the data need to be sorted by itemInSession.\n",
    "\n",
    "As the previous Question, we start by thinking about the query first.\n",
    "\n",
    "1) The expected output is: \"Name of the artist, title of the song and full name of the user\"\n",
    "2) Based on: \"userId and sessionId\"\n",
    "3) Ordered by: \"itemInSession\"\n",
    "\n",
    "From the above three points we know the query to get the data will be a SELECT statement like (camelcase converted to snake_case):\n",
    "\n",
    "```\n",
    "SELECT artist_name, song_title, item_in_session, user_name FROM music_library_by_sessions_and_users\n",
    "WHERE session_id = value AND user_id = value ORDER BY item_in_session\n",
    "\n",
    "```\n",
    "\n",
    "**Note:** `ORDER BY` statement is not actually needed as we will cluster the table by `item_in_session`, I wrote it there just to clarify the query.\n",
    "\n",
    "As we know the SELECT query, we can move to CREATE table query.\n",
    "\n",
    "Before creating the table, we DROP the existing table if it exists, to ensure we start from a clean slate (i.e. to avoid any issue if the code is run twice).\n",
    "\n",
    "We will add NOT EXIST to the CREATE statement to check if the table exists and only create the table if it does not exist. Now we need to select the columns that are going to be in the table and the PRIMARY KEY.\n",
    "\n",
    "(Named: music_library_by_sessions_and_users as per Rubric requirements for tables names as alphanumeric; also as the details of the table is for songs and indexed by sessions and users, it sounds apt to name the table 'music_library_by_sessions_and_users')\n",
    "\n",
    "Column Names: We need names of the artists, titles of the songs, and full names of the users on query upon sessionId and userId, ordered by itemInSession. Hence we will select artist_name , song_title, item_in_session, user_name, session_id and user_id as the names of the columns. For the user_name column, which is the user's full name, we concatenate both `firstName` and `lastName` from the csv file.\n",
    "\n",
    "Primary Key: The PRIMARY key for the table should uniquely identify each row in the table. For us we need results based on sessionId and userId; so we need these both as the primary key\n",
    "\n",
    "Clustering Column: the CLUSTERING COLUMN is the base of which the results will be ordered. Hence, we use itemInSession as the clustering column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artist: Down To The Bone, song: Keep On Keepin' On (item#: 0), user: Sylvie Cruz\n",
      "artist: Three Drives, song: Greece 2000 (item#: 1), user: Sylvie Cruz\n",
      "artist: Sebastien Tellier, song: Kilometer (item#: 2), user: Sylvie Cruz\n",
      "artist: Lonnie Gordon, song: Catch You Baby (Steve Pitron & Max Sanna Radio Edit) (item#: 3), user: Sylvie Cruz\n"
     ]
    }
   ],
   "source": [
    "# CREATE\n",
    "\n",
    "query = \"DROP TABLE IF EXISTS music_library_by_sessions_and_users\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "query = \"\"\"CREATE TABLE IF NOT EXISTS music_library_by_sessions_and_users\n",
    "           (session_id int, user_id int, item_in_session int, artist_name text, song_title text, user_name text, PRIMARY KEY ((session_id, user_id), item_in_session))\"\"\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "    \n",
    "# INSERT\n",
    "\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO music_library_by_sessions_and_users (session_id, user_id, item_in_session, artist_name, song_title, user_name)\"\n",
    "        query = query + \" VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "        session.execute(query, (int(line[8]), int(line[10]), int(line[3]), line[0], line[9], \"{} {}\".format(line[1], line[4])))\n",
    "\n",
    "        \n",
    "# SELECT\n",
    "\n",
    "query = \"\"\"SELECT artist_name, song_title, item_in_session, user_name FROM music_library_by_sessions_and_users\n",
    "           WHERE session_id = 182 AND user_id = 10 ORDER BY item_in_session\"\"\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "    for row in rows:\n",
    "        print (\"artist: {}, song: {} (item#: {}), user: {}\".format(row.artist_name, row.song_title, row.item_in_session, row.user_name))\n",
    "except Exception as e:\n",
    "    print(e)           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "Question 3 expects the users' full names based on a song they have listened to.\n",
    "\n",
    "As the previous Questions, we start by thinking about the query first.\n",
    "\n",
    "1) The expected output is: \"Full name of the user\"\n",
    "2) Based on: \"song title\"\n",
    "\n",
    "From the above two points we know the query to get the data will be a SELECT statement like (camelcase converted to snake_case):\n",
    "\n",
    "```\n",
    "SELECT user_name FROM users_by_songs_and_user_ids WHERE song_title = value\n",
    "\n",
    "```\n",
    "\n",
    "As we know the SELECT query, we can move to CREATE table query.\n",
    "\n",
    "Before creating the table, we DROP the existing table if it exists, to ensure we start from a clean slate (i.e. to avoid any issue if the code is run twice).\n",
    "\n",
    "We will add NOT EXIST to the CREATE statement to check if the table exists and only create the table if it does not exist. Now we need to select the columns that are going to be in the table and the PRIMARY KEY.\n",
    "\n",
    "(Named: users_by_songs_and_user_ids as per Rubric requirements for tables names as alphanumeric; also as the details of the table is for users and indexed by song names and user ids, it sounds apt to name the table 'users_by_songs_and_user_ids')\n",
    "\n",
    "Column Names: We need full names of the users on query upon a song title. We will also need to use user_id as one of the primary keys as values that are guaranteed to be unique (rather than user names). Hence we will select song_title, user_id, and user_name as the names of the columns. For the user_name column, which is the user's full name, we concatenate both `firstName` and `lastName` from the csv file.\n",
    "\n",
    "Primary Key: The PRIMARY key for the table should uniquely identify each row in the table. For us we need results based on song and userId; so we need these both as the primary key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(user_name='Jacqueline Lynch')\n",
      "Row(user_name='Tegan Levine')\n",
      "Row(user_name='Sara Johnson')\n"
     ]
    }
   ],
   "source": [
    "# CREATE\n",
    "\n",
    "query = \"DROP TABLE IF EXISTS users_by_songs_and_user_ids\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "query = \"\"\"CREATE TABLE IF NOT EXISTS users_by_songs_and_user_ids\n",
    "           (song_title text, user_id int, user_name text, PRIMARY KEY (song_title, user_id))\"\"\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "    \n",
    "# INSERT\n",
    "\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO users_by_songs_and_user_ids (song_title, user_id, user_name)\"\n",
    "        query = query + \" VALUES (%s, %s, %s)\"\n",
    "        session.execute(query, (line[9], int(line[10]), \"{} {}\".format(line[1], line[4])))\n",
    "\n",
    "        \n",
    "# SELECT\n",
    "\n",
    "query = \"\"\"SELECT user_name FROM users_by_songs_and_user_ids\n",
    "           WHERE song_title='All Hands Against His Own'\"\"\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "    for row in rows:\n",
    "        print (row)\n",
    "except Exception as e:\n",
    "    print(e)           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    session.execute(\"DROP TABLE IF EXISTS music_library_by_sessions\")\n",
    "    session.execute(\"DROP TABLE IF EXISTS music_library_by_sessions_and_users\")\n",
    "    session.execute(\"DROP TABLE IF EXISTS users_by_songs\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Close the session and cluster connection¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
